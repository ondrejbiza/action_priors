from collections import namedtuple
from enum import Enum

# there are many constants since I use this for other projects as well
# these constants are mostly used in configuration files
# I create an Enum Constants programatically, so that I can check that each constant is declared only once
constants = [
    "STATES", "STATE_LABELS", "ACTIONS", "REWARDS", "QS", "NEXT_STATES", "NEXT_STATE_LABELS",
    "COMMAND", "NUM_EXP", "TIMESTAMP", "INPUT_SIZE", "NEURONS", "USE_BATCH_NORM", "USE_LAYER_NORM",
    "ACTIVATION_LAST", "NUM_COMPONENTS", "NUM_ACTIONS", "BETA", "NO_SAMPLE", "FREEZE_HMM_VAR",
    "FREEZE_HMM_PRIOR", "NO_NEXT_GRAD", "NO_HMM", "USE_SOFTPLUS", "LOAD_PATH", "LATENT_SIZE",
    "ENCODER_LEARNING_RATE", "PRIOR_LEARNING_RATE", "ENCODER_WEIGHT_DECAY", "PRIOR_WEIGHT_DECAY",
    "VALIDATION_FRACTION", "BATCH_SIZE", "DISCOUNT", "GT_QS", "LOG_QS", "ZERO_ONE_QS", "UNIT_NORMAL_QS",
    "PLOT_DATASET_EXAMPLES", "NUM_TRAINING_STEPS", "DEVICE", "MODEL_SAVE_PATH", "MODEL_LOAD_PATH",
    "QS_FACTOR", "PLOT_RESULTS", "HMM_MU_INIT_SD", "HMM_SIGMA_INIT_VAL", "FILTER_SIZES", "FILTER_COUNTS",
    "STRIDES", "FLAT_OUTPUT", "DOUBLE_LEARNING", "PRIORITIZED_REPLAY", "TOTAL_REWARDS", "DISCOUNTED_REWARDS",
    "TMP_REWARDS", "DUELING", "LEARNING_RATE", "GOAL", "MAX_STEPS", "MAX_EPISODES", "EXPLORATION_STEPS",
    "PRIORITIZED_REPLAY_MAX_STEPS", "BUFFER_SIZE", "TARGET_NETWORK", "TARGET_NETWORK_SYNC",
    "ABSTRACT_ACTIONS", "DONES", "NUM_FRUITS", "REACHED_GOAL", "WEIGHT_DECAY", "EPS", "GMM_MU_INIT_SD",
    "GMM_SIGMA_INIT_VAL", "FULLY_CONV", "FREEZE_GMM_VAR", "FREEZE_GMM_PRIOR", "ANIMATE_LATENT",
    "NO_ENCODER_BETA_LOSS", "PSEUDO_GT_QS", "PLOT_ABSTRACTION_EXAMPLES", "PURITIES", "SIZES", "MEAN_PURITY",
    "INVERSE_PURITIES", "MEAN_INVERSE_PURITY", "TASK_INDEX", "TASK_LIST", "IGNORE_LIST", "EVAL_TOTAL_REWARDS",
    "EVAL_DISCOUNTED_TOTAL_REWARDS", "EVAL_NUM_STEPS", "USE_ADVANTAGES", "FINE_LABELS", "NUM_TASKS",
    "ZERO_ONE_QS_ALL_TASKS", "POLICY", "SOFTMAX", "INIT_TAU", "FINAL_TAU", "USE_LOG_ADVANTAGES",
    "HAND_STATES", "NEXT_HAND_STATES", "SIMULATOR", "ROBOT", "WORKSPACE", "HEIGHTMAP_SIZE", "NUM_OBJECTS",
    "ACTION_SEQUENCE", "NUM_PROCESSES", "NUM_SAMPLES", "SAVE_PATH", "NUM_ROTATIONS",
    "HAND_BITS", "OBS", "HAND_OBS", "NEXT_HAND_BITS", "NEXT_OBS", "NEXT_HAND_OBS", "STEPS_LEFT",
    "PRIORITIZED_BUFFER", "PRIORITIZED_BUFFER_EXPERT", "EXPERT_BUFFER", "BUFFER", "PATCH_SIZE",
    "ACTION_SPACE", "MARGIN", "MARGIN_L", "MARGIN_WEIGHT", "MARGIN_BETA", "DIVIDE_FACTOR", "PER_ALPHA",
    "INIT_EPS", "FINAL_EPS", "PER_EXPERT_EPS", "PER_EPS", "PER_BETA", "INIT_COEF", "FINAL_COEF",
    "TARGET_UPDATE_FREQ", "FIXED_EPS", "TRUE_RANDOM", "TRAINING_OFFSET", "TRAINING_ITERS",
    "BUFFER_TYPE", "EXPERT_FRACTION", "TOTAL_LOSS", "TD_ERROR", "ORIG_ACTIONS", "DATASET_LOAD_PATH",
    "TOTAL_VALID_LOSS", "ACCURACY", "VALID_ACCURACY", "VALIDATION_FREQ", "ADVS", "LOG_ADVS", "IS_OPT",
    "ALLOWED_TASKS", "DISCRETIZE_QS_NUM_BINS", "LIMIT", "POST_EPS", "NORMALIZE_STATE",
    "INITIALIZE_GMM_WITH_EMBEDDINGS", "USE_HEIGHT_HEURISTIC", "TASK_CLASSIFIER_LOAD_PATH",
    "TASK_CLASSIFIER_THRESHOLD", "GET_CUSTOM_LABELS", "LABELS_INTO_BINARY", "LABEL_MEAN_PURITY",
    "SCORES_LOAD_PATH", "NUM_EVAL_EPISODES", "MINMAX_VAR", "NUM_POSITIVE_ACTIONS", "NUM_NEGATIVE_ACTIONS",
    "ORIG_POSITIVE_ACTIONS", "MAX_Q_TOLERANCE", "BALANCE_LOSS", "BINARY_LABELS", "USE_BINARY_LABELS",
    "POSITIVE_LABELS", "AMBIGUOUS_LABELS", "POS_AMB_LABELS_LOAD_PATH", "AMB_QS", "USE_AMB_LABELS",
    "ALG", "FAKE_EXPERT", "TAU", "NUM_HEADS", "TEACHER_LOAD_PATHS", "GOALS", "EPSILON", "LOSS", "SIDE_TRANSFER",
    "FREEZE_ENCODER", "SIDE_TRANSFER_LAST"
]

# all constants must be unique
assert len(constants) == len(set(constants))

Constants = Enum("Constants", {
    c: c for c in constants
})

OPT_SUFFIX = "_opt.npy"
AMB_SUFFIX = "_amb.npy"

# named tuples
ExpertTransition = namedtuple('ExpertTransition', 'state obs action reward next_state next_obs done step_left expert')

# TODO: fill in if you want to use Sacred with MongoDB
MONGO_URI = None
DB_NAME = None
